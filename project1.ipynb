{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1622ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Create a GUI window\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "# Open a file dialog for selecting a folder\n",
    "folder_path = filedialog.askdirectory()\n",
    "\n",
    "# Print the path of the selected folder\n",
    "print(\"Selected folder:\", folder_path)\n",
    "\n",
    "\n",
    "# Set the path to the folder of images\n",
    "path = folder_path\n",
    "\n",
    "# Set the percentage of images to use for testing\n",
    "test_percent = float(input(\"Enter percentage of images to use for testing (0-1): \"))\n",
    "\n",
    "# Set the paths for the training and testing folders\n",
    "train_path = os.path.join(path, \"train\")\n",
    "test_path = os.path.join(path, \"test\")\n",
    "\n",
    "# Create the training and testing folders if they don't exist\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "# Get a list of all the image files in the folder\n",
    "image_files = [f for f in os.listdir(path) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "\n",
    "# Calculate the number of images to use for testing\n",
    "num_test = int(test_percent * len(image_files))\n",
    "\n",
    "# Shuffle the list of image files\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# Move the first num_test images to the testing folder\n",
    "for i in range(num_test):\n",
    "    src = os.path.join(path, image_files[i])\n",
    "    dst = os.path.join(test_path, image_files[i])\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "# Move the remaining images to the training folder\n",
    "for i in range(num_test, len(image_files)):\n",
    "    src = os.path.join(path, image_files[i])\n",
    "    dst = os.path.join(train_path, image_files[i])\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29293c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d5935e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0          1       0       0       0       0       0       0       0       0   \n",
      "1          0       0       0       0       0       0       0       0       0   \n",
      "2          1       0       0       0       0       0       0       0       0   \n",
      "3          4       0       0       0       0       0       0       0       0   \n",
      "4          0       0       0       0       0       0       0       0       0   \n",
      "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "41995      0       0       0       0       0       0       0       0       0   \n",
      "41996      1       0       0       0       0       0       0       0       0   \n",
      "41997      7       0       0       0       0       0       0       0       0   \n",
      "41998      6       0       0       0       0       0       0       0       0   \n",
      "41999      9       0       0       0       0       0       0       0       0   \n",
      "\n",
      "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0           0  ...         0         0         0         0         0   \n",
      "1           0  ...         0         0         0         0         0   \n",
      "2           0  ...         0         0         0         0         0   \n",
      "3           0  ...         0         0         0         0         0   \n",
      "4           0  ...         0         0         0         0         0   \n",
      "...       ...  ...       ...       ...       ...       ...       ...   \n",
      "41995       0  ...         0         0         0         0         0   \n",
      "41996       0  ...         0         0         0         0         0   \n",
      "41997       0  ...         0         0         0         0         0   \n",
      "41998       0  ...         0         0         0         0         0   \n",
      "41999       0  ...         0         0         0         0         0   \n",
      "\n",
      "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0             0         0         0         0         0  \n",
      "1             0         0         0         0         0  \n",
      "2             0         0         0         0         0  \n",
      "3             0         0         0         0         0  \n",
      "4             0         0         0         0         0  \n",
      "...         ...       ...       ...       ...       ...  \n",
      "41995         0         0         0         0         0  \n",
      "41996         0         0         0         0         0  \n",
      "41997         0         0         0         0         0  \n",
      "41998         0         0         0         0         0  \n",
      "41999         0         0         0         0         0  \n",
      "\n",
      "[42000 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67c2ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(tdata,val):\n",
    "    len1= int(len(tdata)*val)\n",
    "    t1 = tdata.sample(frac=1)\n",
    "    val_data = t1.iloc[0:len1,:]\n",
    "    train = t1.iloc[len1:,:]\n",
    "    return val_data,train\n",
    "\n",
    "v,d = sampling(df,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f89d00a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8400, 785)\n"
     ]
    }
   ],
   "source": [
    "print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39819cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(train,batch_size):\n",
    "    count = 0\n",
    "    while count<len(train):\n",
    "        data = train.iloc[count:count+batch_size,:]\n",
    "        X = data.iloc[:,1:]\n",
    "        Y = data.iloc[:,0]\n",
    "        yield X.values,Y.values\n",
    "        count+=batch_size\n",
    "    \n",
    "    \n",
    "gen= generator(d,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3753307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_new(train,batch_size):\n",
    "    count = 0\n",
    "    while count<len(train):\n",
    "        data = train.iloc[count:count+batch_size,:]\n",
    "        X = data.iloc[:,1:]\n",
    "        Y = data.iloc[:,0]\n",
    "        return X,Y\n",
    "        count+=batch_size\n",
    "    \n",
    "    \n",
    "gen= generator(d,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ba60836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), array([7, 4, 1, 0, 0, 8, 5, 9], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "165ce3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork:\n",
    "    def __init__(self,learning_rate):\n",
    "        self.weights = np.array([np.random.randn(),np.random.randn()])\n",
    "        self.bias = np.random.randn()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def sigmoid_deriv(self,x):\n",
    "        return self.sigmoid(x)*(1-self.sigmoid(x))\n",
    "    \n",
    "    def predict(self,input):\n",
    "        l1 = np.dot(input,self.weights) + self.bias\n",
    "        l2 = self.sigmoid(l1)\n",
    "        prediction = l2\n",
    "        return prediction\n",
    "    \n",
    "    def gradients(self,input,target):\n",
    "        l1 = np.dot(input,self.weights) + self.bias\n",
    "        l2 = self.sigmoid(l1)\n",
    "        prediction = l2\n",
    "\n",
    "        error_prediction = 2*(prediction-target)\n",
    "        prediction_l1 = self.sigmoid_deriv(l1)\n",
    "        l1_bias = 1\n",
    "        l1_weight = (0*self.weights)+(1*input)\n",
    "        error_bias = (error_prediction*prediction_l1*l1_bias)\n",
    "        error_weights = (error_prediction*prediction_l1*l1_weight)\n",
    "\n",
    "        return error_bias,error_weights\n",
    "\n",
    "    def update_params(self,error_bias,error_weights):\n",
    "        self.bias = self.bias - (error_bias*self.learning_rate)\n",
    "        self.weights = self.weights - (error_weights*self.learning_rate)\n",
    "\n",
    "\n",
    "    def train(self,input,target,iterations):\n",
    "        errors = []\n",
    "        for current in range(iterations):\n",
    "            random_index = np.random.randint(len(input))\n",
    "\n",
    "            input = input[random_index]\n",
    "            target = target[random_index]\n",
    "\n",
    "            #Compute gradients and update weights\n",
    "            error_bias,error_weights = self.gradients(input,target)\n",
    "            self.update_params(error_bias,error_weights)\n",
    "\n",
    "            #Measure error for iterations \n",
    "            if current%100==0:\n",
    "                cum_error = 0\n",
    "                # Loop through all instances to measure the error\n",
    "                for each_instance in range(len(input)):\n",
    "                    data_point = input[each_instance]\n",
    "                    target = target[each_instance]\n",
    "\n",
    "                    prediction = self.predict(data_point)\n",
    "                    error = np.square(prediction-target)\n",
    "                    cum_error = cum_error + error\n",
    "                errors.append(cum_error)\n",
    "\n",
    "        return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e208914",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), slice(1, None, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), slice(1, None, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21216\\3662323544.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mv_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mv_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mgenerator1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3634\u001b[0m                 \u001b[1;31m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3635\u001b[0m                 \u001b[1;31m#  the TypeError.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3636\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3637\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5649\u001b[0m             \u001b[1;31m# if key is not a scalar, directly raise an error (the code below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5650\u001b[0m             \u001b[1;31m# would convert to numpy arrays and raise later any way) - GH29926\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5651\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5653\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), slice(1, None, None))"
     ]
    }
   ],
   "source": [
    "model_net = []\n",
    "for i in range(5):\n",
    "    v,d = sampling(df,0.2)\n",
    "    v_data = v[:,1:]\n",
    "    v_label = v[:,0]\n",
    "    generator1 = generator_new(d,64)\n",
    "    x,y = generator1\n",
    "    learning_rate = 0.1\n",
    "    nn = neuralNetwork(learning_rate)\n",
    "    nn.train(x,y,50)\n",
    "    model_net.append(nn)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b23246",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_net:\n",
    "    prediction = model.predict(v_data)\n",
    "    label_op.append(prediction)\n",
    "    validation \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2650d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_op = []\n",
    "input \n",
    "for model in model_net:\n",
    "    prediction = model.predict(v_data)\n",
    "    label_op.append(prediction)\n",
    "max = 0\n",
    "res = label_op[0]\n",
    "for i in label_op:\n",
    "    freq = label_op.count(i)\n",
    "    if freq > max:\n",
    "        max = freq\n",
    "        res = i\n",
    "        \n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
